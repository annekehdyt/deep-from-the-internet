{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 100\n",
    "N_HIDDEN_HL1 = 10\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "seed(RANDOM_STATE)\n",
    "set_random_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pickle(path):\n",
    "    import pickle\n",
    "    with open(path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtrain.pickle')\n",
    "X_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_xtest.pickle')\n",
    "y_train_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytrain.pickle')\n",
    "y_test_original = open_pickle('../../data/imdb/imdb_original_preprocessed_ytest.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "cv = CountVectorizer(min_df = 100, token_pattern=token, lowercase=True, binary=True)\n",
    "X_train = cv.fit_transform(X_train_original)\n",
    "X_test = cv.transform(X_test_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = np.expand_dims(X_train, axis=0)\n",
    "X_te = np.expand_dims(X_test, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3686)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = np.reshape(y_train_original, (len(y_train_original), 1))\n",
    "y_te = np.reshape(y_test_original, (len(y_test_original), 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start here\n",
    "\n",
    "minimizing -cost is the same as maximizing cost <br>\n",
    "    \n",
    "https://github.com/Mazecreator/tensorflow-hints/tree/master/maximize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 100 loss: 0.83208936\n",
      "Epoch 1 out of 100 loss: 0.733825\n",
      "Epoch 2 out of 100 loss: 0.74395955\n",
      "Epoch 3 out of 100 loss: 0.69092596\n",
      "Epoch 4 out of 100 loss: 0.62532955\n",
      "Epoch 5 out of 100 loss: 0.59395814\n",
      "Epoch 6 out of 100 loss: 0.5860601\n",
      "Epoch 7 out of 100 loss: 0.5667688\n",
      "Epoch 8 out of 100 loss: 0.5333006\n",
      "Epoch 9 out of 100 loss: 0.5025065\n",
      "Epoch 10 out of 100 loss: 0.4852207\n",
      "Epoch 11 out of 100 loss: 0.47732538\n",
      "Epoch 12 out of 100 loss: 0.46836406\n",
      "Epoch 13 out of 100 loss: 0.4536153\n",
      "Epoch 14 out of 100 loss: 0.43621013\n",
      "Epoch 15 out of 100 loss: 0.42164472\n",
      "Epoch 16 out of 100 loss: 0.4123388\n",
      "Epoch 17 out of 100 loss: 0.40635163\n",
      "Epoch 18 out of 100 loss: 0.4000635\n",
      "Epoch 19 out of 100 loss: 0.3915218\n",
      "Epoch 20 out of 100 loss: 0.38148963\n",
      "Epoch 21 out of 100 loss: 0.37208763\n",
      "Epoch 22 out of 100 loss: 0.36480305\n",
      "Epoch 23 out of 100 loss: 0.35948133\n",
      "Epoch 24 out of 100 loss: 0.35479367\n",
      "Epoch 25 out of 100 loss: 0.34948945\n",
      "Epoch 26 out of 100 loss: 0.34330484\n",
      "Epoch 27 out of 100 loss: 0.33692867\n",
      "Epoch 28 out of 100 loss: 0.33127272\n",
      "Epoch 29 out of 100 loss: 0.32674474\n",
      "Epoch 30 out of 100 loss: 0.32303974\n",
      "Epoch 31 out of 100 loss: 0.31949773\n",
      "Epoch 32 out of 100 loss: 0.31564936\n",
      "Epoch 33 out of 100 loss: 0.31151384\n",
      "Epoch 34 out of 100 loss: 0.30747566\n",
      "Epoch 35 out of 100 loss: 0.3039228\n",
      "Epoch 36 out of 100 loss: 0.3009499\n",
      "Epoch 37 out of 100 loss: 0.29833397\n",
      "Epoch 38 out of 100 loss: 0.29574794\n",
      "Epoch 39 out of 100 loss: 0.2930126\n",
      "Epoch 40 out of 100 loss: 0.29019246\n",
      "Epoch 41 out of 100 loss: 0.28749397\n",
      "Epoch 42 out of 100 loss: 0.28507757\n",
      "Epoch 43 out of 100 loss: 0.28294092\n",
      "Epoch 44 out of 100 loss: 0.28094366\n",
      "Epoch 45 out of 100 loss: 0.2789318\n",
      "Epoch 46 out of 100 loss: 0.27685073\n",
      "Epoch 47 out of 100 loss: 0.27476314\n",
      "Epoch 48 out of 100 loss: 0.27277583\n",
      "Epoch 49 out of 100 loss: 0.2709493\n",
      "Epoch 50 out of 100 loss: 0.2692567\n",
      "Epoch 51 out of 100 loss: 0.26761827\n",
      "Epoch 52 out of 100 loss: 0.26596868\n",
      "Epoch 53 out of 100 loss: 0.26430207\n",
      "Epoch 54 out of 100 loss: 0.2626641\n",
      "Epoch 55 out of 100 loss: 0.2611061\n",
      "Epoch 56 out of 100 loss: 0.25964293\n",
      "Epoch 57 out of 100 loss: 0.2582477\n",
      "Epoch 58 out of 100 loss: 0.2568779\n",
      "Epoch 59 out of 100 loss: 0.25551027\n",
      "Epoch 60 out of 100 loss: 0.25415292\n",
      "Epoch 61 out of 100 loss: 0.25283325\n",
      "Epoch 62 out of 100 loss: 0.25157082\n",
      "Epoch 63 out of 100 loss: 0.25036347\n",
      "Epoch 64 out of 100 loss: 0.24919116\n",
      "Epoch 65 out of 100 loss: 0.2480338\n",
      "Epoch 66 out of 100 loss: 0.24688603\n",
      "Epoch 67 out of 100 loss: 0.24575666\n",
      "Epoch 68 out of 100 loss: 0.24466012\n",
      "Epoch 69 out of 100 loss: 0.24360098\n",
      "Epoch 70 out of 100 loss: 0.24257258\n",
      "Epoch 71 out of 100 loss: 0.24156332\n",
      "Epoch 72 out of 100 loss: 0.24056566\n",
      "Epoch 73 out of 100 loss: 0.2395809\n",
      "Epoch 74 out of 100 loss: 0.23861547\n",
      "Epoch 75 out of 100 loss: 0.23767465\n",
      "Epoch 76 out of 100 loss: 0.23675837\n",
      "Epoch 77 out of 100 loss: 0.2358607\n",
      "Epoch 78 out of 100 loss: 0.23497613\n",
      "Epoch 79 out of 100 loss: 0.23410301\n",
      "Epoch 80 out of 100 loss: 0.23324399\n",
      "Epoch 81 out of 100 loss: 0.23240253\n",
      "Epoch 82 out of 100 loss: 0.23157953\n",
      "Epoch 83 out of 100 loss: 0.23077303\n",
      "Epoch 84 out of 100 loss: 0.22997983\n",
      "Epoch 85 out of 100 loss: 0.22919776\n",
      "Epoch 86 out of 100 loss: 0.22842726\n",
      "Epoch 87 out of 100 loss: 0.22767012\n",
      "Epoch 88 out of 100 loss: 0.22692706\n",
      "Epoch 89 out of 100 loss: 0.22619805\n",
      "Epoch 90 out of 100 loss: 0.22548105\n",
      "Epoch 91 out of 100 loss: 0.22477436\n",
      "Epoch 92 out of 100 loss: 0.22407766\n",
      "Epoch 93 out of 100 loss: 0.22339176\n",
      "Epoch 94 out of 100 loss: 0.2227173\n",
      "Epoch 95 out of 100 loss: 0.22205399\n",
      "Epoch 96 out of 100 loss: 0.22140098\n",
      "Epoch 97 out of 100 loss: 0.22075744\n",
      "Epoch 98 out of 100 loss: 0.22012271\n",
      "Epoch 99 out of 100 loss: 0.219497\n",
      "Accuracy 0.8773999810218811\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X_train_tensor = tf.placeholder(tf.float32, [None, X_train.shape[1]], name='review')\n",
    "Y_train_tensor = tf.placeholder(tf.float32, [None, 1], name='label')\n",
    "\n",
    "W = tf.get_variable(name='weights',\n",
    "                   shape=(X_train.shape[1], 1), \n",
    "                   initializer=tf.initializers.glorot_uniform(seed=RANDOM_STATE))\n",
    "\n",
    "b = tf.get_variable(name='bias', \n",
    "                   initializer=tf.constant(1.0))\n",
    "\n",
    "# Final output logits\n",
    "logits = tf.matmul(X_train_tensor, W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y_train_tensor))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "preds = tf.nn.sigmoid(logits)\n",
    "correct_preds = tf.equal(tf.cast(tf.greater(preds, tf.constant(0.5)), tf.float32), \n",
    "                         Y_train_tensor)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/imdb_simple', tf.get_default_graph())\n",
    "\n",
    "# Start the session\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        \n",
    "        _, loss_per_epoch = sess.run([optimizer, loss], \n",
    "                           feed_dict={X_train_tensor: X_train, Y_train_tensor: y_tr})\n",
    "        \n",
    "        print('Epoch', epoch, 'out of', EPOCHS, 'loss:', loss_per_epoch)\n",
    "    \n",
    "    accuracy_test = sess.run(accuracy, \n",
    "                             feed_dict={X_train_tensor: X_test, Y_train_tensor: y_te})\n",
    "    \n",
    "    print('Accuracy {0}'.format(accuracy_test))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human term IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_unigrams(path, X, y):\n",
    "    word_list = []\n",
    "    connotation = {}\n",
    "    \n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            word_list.append(line.strip())\n",
    "            \n",
    "    for word in word_list:\n",
    "        pos_count = 0\n",
    "        neg_count = 0\n",
    "        for i, doc in enumerate(X):\n",
    "            if word in doc.lower():\n",
    "                \n",
    "                if (y[i] == 1):\n",
    "                    pos_count += 1\n",
    "                else:\n",
    "                    neg_count += 1\n",
    "                    \n",
    "        if pos_count > neg_count:\n",
    "            connotation[word] = 1\n",
    "        else:\n",
    "            connotation[word] = 0\n",
    "    \n",
    "    return word_list, connotation\n",
    "\n",
    "def generate_appearance(X_train_corpus, X_test_corpus, word_list, connotation):\n",
    "    y_train_agreement = []\n",
    "    for i in range(len(X_train_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_train_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_train_agreement.append(doc_agreement)\n",
    "        \n",
    "    y_test_agreement = []\n",
    "    for i in range(len(X_test_corpus)):\n",
    "        doc_agreement = []\n",
    "        for word in word_list:\n",
    "            if word in X_test_corpus[i]:\n",
    "                if connotation[word] == 1:\n",
    "                    doc_agreement.append(1)\n",
    "                else:\n",
    "                    doc_agreement.append(-1)\n",
    "            else:\n",
    "                doc_agreement.append(0)\n",
    "        y_test_agreement.append(doc_agreement)\n",
    "        \n",
    "    return np.array(y_train_agreement), np.array(y_test_agreement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list, connotation = load_unigrams('./imdb-unigrams.txt', X_train_original, y_train_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 out of 100 loss: 0.83208936\n",
      "Epoch 1 out of 100 loss: 0.733825\n",
      "Epoch 2 out of 100 loss: 0.74395955\n",
      "Epoch 3 out of 100 loss: 0.69092596\n",
      "Epoch 4 out of 100 loss: 0.62532955\n",
      "Epoch 5 out of 100 loss: 0.59395814\n",
      "Epoch 6 out of 100 loss: 0.5860601\n",
      "Epoch 7 out of 100 loss: 0.5667688\n",
      "Epoch 8 out of 100 loss: 0.5333006\n",
      "Epoch 9 out of 100 loss: 0.5025065\n",
      "Epoch 10 out of 100 loss: 0.4852207\n",
      "Epoch 11 out of 100 loss: 0.47732538\n",
      "Epoch 12 out of 100 loss: 0.46836406\n",
      "Epoch 13 out of 100 loss: 0.4536153\n",
      "Epoch 14 out of 100 loss: 0.43621013\n",
      "Epoch 15 out of 100 loss: 0.42164472\n",
      "Epoch 16 out of 100 loss: 0.4123388\n",
      "Epoch 17 out of 100 loss: 0.40635163\n",
      "Epoch 18 out of 100 loss: 0.4000635\n",
      "Epoch 19 out of 100 loss: 0.3915218\n",
      "Epoch 20 out of 100 loss: 0.38148963\n",
      "Epoch 21 out of 100 loss: 0.37208763\n",
      "Epoch 22 out of 100 loss: 0.36480305\n",
      "Epoch 23 out of 100 loss: 0.35948133\n",
      "Epoch 24 out of 100 loss: 0.35479367\n",
      "Epoch 25 out of 100 loss: 0.34948945\n",
      "Epoch 26 out of 100 loss: 0.34330484\n",
      "Epoch 27 out of 100 loss: 0.33692867\n",
      "Epoch 28 out of 100 loss: 0.33127272\n",
      "Epoch 29 out of 100 loss: 0.32674474\n",
      "Epoch 30 out of 100 loss: 0.32303974\n",
      "Epoch 31 out of 100 loss: 0.31949773\n",
      "Epoch 32 out of 100 loss: 0.31564936\n",
      "Epoch 33 out of 100 loss: 0.31151384\n",
      "Epoch 34 out of 100 loss: 0.30747566\n",
      "Epoch 35 out of 100 loss: 0.3039228\n",
      "Epoch 36 out of 100 loss: 0.3009499\n",
      "Epoch 37 out of 100 loss: 0.29833397\n",
      "Epoch 38 out of 100 loss: 0.29574794\n",
      "Epoch 39 out of 100 loss: 0.2930126\n",
      "Epoch 40 out of 100 loss: 0.29019246\n",
      "Epoch 41 out of 100 loss: 0.28749397\n",
      "Epoch 42 out of 100 loss: 0.28507757\n",
      "Epoch 43 out of 100 loss: 0.28294092\n",
      "Epoch 44 out of 100 loss: 0.28094366\n",
      "Epoch 45 out of 100 loss: 0.2789318\n",
      "Epoch 46 out of 100 loss: 0.27685073\n",
      "Epoch 47 out of 100 loss: 0.27476314\n",
      "Epoch 48 out of 100 loss: 0.27277583\n",
      "Epoch 49 out of 100 loss: 0.2709493\n",
      "Epoch 50 out of 100 loss: 0.2692567\n",
      "Epoch 51 out of 100 loss: 0.26761827\n",
      "Epoch 52 out of 100 loss: 0.26596868\n",
      "Epoch 53 out of 100 loss: 0.26430207\n",
      "Epoch 54 out of 100 loss: 0.2626641\n",
      "Epoch 55 out of 100 loss: 0.2611061\n",
      "Epoch 56 out of 100 loss: 0.25964293\n",
      "Epoch 57 out of 100 loss: 0.2582477\n",
      "Epoch 58 out of 100 loss: 0.2568779\n",
      "Epoch 59 out of 100 loss: 0.25551027\n",
      "Epoch 60 out of 100 loss: 0.25415292\n",
      "Epoch 61 out of 100 loss: 0.25283325\n",
      "Epoch 62 out of 100 loss: 0.25157082\n",
      "Epoch 63 out of 100 loss: 0.25036347\n",
      "Epoch 64 out of 100 loss: 0.24919116\n",
      "Epoch 65 out of 100 loss: 0.2480338\n",
      "Epoch 66 out of 100 loss: 0.24688603\n",
      "Epoch 67 out of 100 loss: 0.24575666\n",
      "Epoch 68 out of 100 loss: 0.24466012\n",
      "Epoch 69 out of 100 loss: 0.24360098\n",
      "Epoch 70 out of 100 loss: 0.24257258\n",
      "Epoch 71 out of 100 loss: 0.24156332\n",
      "Epoch 72 out of 100 loss: 0.24056566\n",
      "Epoch 73 out of 100 loss: 0.2395809\n",
      "Epoch 74 out of 100 loss: 0.23861547\n",
      "Epoch 75 out of 100 loss: 0.23767465\n",
      "Epoch 76 out of 100 loss: 0.23675837\n",
      "Epoch 77 out of 100 loss: 0.2358607\n",
      "Epoch 78 out of 100 loss: 0.23497613\n",
      "Epoch 79 out of 100 loss: 0.23410301\n",
      "Epoch 80 out of 100 loss: 0.23324399\n",
      "Epoch 81 out of 100 loss: 0.23240253\n",
      "Epoch 82 out of 100 loss: 0.23157953\n",
      "Epoch 83 out of 100 loss: 0.23077303\n",
      "Epoch 84 out of 100 loss: 0.22997983\n",
      "Epoch 85 out of 100 loss: 0.22919776\n",
      "Epoch 86 out of 100 loss: 0.22842726\n",
      "Epoch 87 out of 100 loss: 0.22767012\n",
      "Epoch 88 out of 100 loss: 0.22692706\n",
      "Epoch 89 out of 100 loss: 0.22619805\n",
      "Epoch 90 out of 100 loss: 0.22548105\n",
      "Epoch 91 out of 100 loss: 0.22477436\n",
      "Epoch 92 out of 100 loss: 0.22407766\n",
      "Epoch 93 out of 100 loss: 0.22339176\n",
      "Epoch 94 out of 100 loss: 0.2227173\n",
      "Epoch 95 out of 100 loss: 0.22205399\n",
      "Epoch 96 out of 100 loss: 0.22140098\n",
      "Epoch 97 out of 100 loss: 0.22075744\n",
      "Epoch 98 out of 100 loss: 0.22012271\n",
      "Epoch 99 out of 100 loss: 0.219497\n",
      "Accuracy 0.8773999810218811\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, X_train.shape[1]], name='review')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='label')\n",
    "\n",
    "W = tf.get_variable(name='weights',\n",
    "                   shape=(X_train.shape[1], 1), \n",
    "                   initializer=tf.initializers.glorot_uniform(seed=RANDOM_STATE))\n",
    "\n",
    "b = tf.get_variable(name='bias', \n",
    "                   initializer=tf.constant(1.0))\n",
    "\n",
    "# Final output logits\n",
    "relu_op = tf.nn.relu(X)\n",
    "logits = tf.matmul(relu_op, W) + b\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,\n",
    "                                                             labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(loss)\n",
    "\n",
    "preds = tf.nn.sigmoid(logits)\n",
    "correct_preds = tf.equal(tf.cast(tf.greater(preds, tf.constant(0.5)), tf.float32), \n",
    "                         Y)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "writer = tf.summary.FileWriter('./graphs/imdb_simple', tf.get_default_graph())\n",
    "\n",
    "# Start the session\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        \n",
    "        _, loss_per_epoch = sess.run([optimizer, loss], \n",
    "                           feed_dict={X: X_train, Y: y_tr})\n",
    "        \n",
    "        print('Epoch', epoch, 'out of', EPOCHS, 'loss:', loss_per_epoch)\n",
    "    \n",
    "    accuracy_test = sess.run(accuracy, \n",
    "                             feed_dict={X: X_test, Y: y_te})\n",
    "    \n",
    "    print('Accuracy {0}'.format(accuracy_test))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
